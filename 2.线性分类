0.回顾
通过打开不同的特点转变成新的模型
线性：
属性非线性--特征转换（多项式回归）
全局非线性--线性分类（激活函数非线性）
系数非线性--神经网络
全局性--线性样条回归（分割样本空间），决策树
数据未加工--PCA，流形
0.1.线性分类
从线性回归出发，通过激活函数转换为0/1；从降维的角度，从P维数据变换为1维数据
硬分类：输出{0，1}，线性判别分析(fisher)，感知机
软分类：输出(0，1)，生成式模型(Gaussian Discriminant Analysis)；判别式模型(Logistic Regression)；

1.感知机  
想法：错误驱动
模型：f(x) = sign(w^t x), x;w R^p    sign(a) = 1 a>0; -1 a<0
策略：loss function
D:{被错误分类的样本}
L(w) = 错误分类数量；但不可导
可改为L(w) = 错位分类的点 sum y_i w^T x_i
算法：SGD，梯度下降迭代w

2.线性判别(fisher判别分析)
数据 X；Y；y_i {-1,1}
思想：在一个合适的投影方向进行投影（降维），类内差异小类间差异大
  类间：类间均值的欧氏距离
  类内：用方差表示
目标函数：类间/（类内）J(w) = (z_1-z_2)^2 / S_1 + S_2
argmax J(w) = w^T (x_c1 - x_c2)(x_c1-x_c2)^T w /(w_T (s_c1 + s_c2)w)
s为方差，c1 c2 为两个类别内的数据样本

3.高斯判别


4.朴素贝叶斯
