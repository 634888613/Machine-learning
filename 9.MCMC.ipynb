{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "近似推断/精确推断，其中近似推断重的随即推断中最著名的即为MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一.Monte Carlo Method(几种采样方法)  \n",
    "采样的动机：1）采样本身；2）求和或求积分      \n",
    "什么是好样本：1）样本趋向于高概率区域；2）样本之间相互独立。但是直接采样是困难的：1）配分函数难以计算(p(x)=\\frac{1}{Z})\\hat{p(x)}；2）高维难以计算，状态空间K^p（K个状态，P个维度）        \n",
    "推断的主要作用是计算后验概率，得到后验计算其期望是关键问题，后验往往使用数值方式进行模拟\\sum   \n",
    "采样方法： \n",
    "概率分布采样，如果能计算出cdf，可以通过与[0,1]上的均匀分布关联可以进行随机采样，利用cdf的反函数回推，但是对于很多概率密度函数，pdf难以推导出cdf  \n",
    "Rejection Sampling，假设一个q(z):proposed distribution，对于任意$Z_i$,$Mq(z)>=p(z)$，\\alpha：接收率，$\\alpha=\\frac{p(z^i)}{Mq(z^i)}$,$0<=\\alpha<=1$,z^i~q(z);u~U(0,1),如果u>=\\alpha，接受z^i，但是这个方法十分依赖q函数的选择，并且在高维空间由于相差较大，采样效率很低  \n",
    "重要性采样：不对p(z)进行采样，而是对其期望进行采样  \n",
    "$E_{p(z)}[f(z)]=\\int p(z)f(z)dz=\\int \\frac{p(z)}{q(z)}q(z)f(z)dz=\\int f(z)\\frac{p(z)}{q(z)}q(z)dz=\\frac{1}{N} \\sum_{i=1}^N f(z_i)\\frac{p(z_i)}{q(z_i)}$,$z_i~q(z)$，weight $\\frac{p(z_i)}{q(z_i)}$,但是这个方法也依赖于q(z)的选择    \n",
    "重要性采样的一个变种，Sampline-Importance-Resampling,两阶段的重要性采样，第一次采样可能不均匀，引入第二个阶段，以weight为概率值从第一次的采样中再次采样 \n",
    "这两大类方法可以理解为寻找一个q(x)来逼近p(x)进而取样，要求两个函数接近"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二.马氏链  \n",
    "随机过程所研究的是随机变量序列，马氏链是一种特殊的随机过程，$P(X_{t+1}=x|X_1,...X_t)=P(X_{t+1}|X_t)$，时间和状态均为离散${X_t}$,P->状态转移矩阵$[P_{ij}]$，从概率图的角度可以写为 $x_1->x_2->...->x_t->x_{t+1}$,不同时刻对应一个概率分布$\\pi_i,\\pi_{t+1}(x^*)=\\int \\pi_t(x)p(x->x*)dx$  \n",
    "随机矩阵：特征值的绝对值<=1 =>Q=A \\lambda A^{-1},\\lambda对角阵，且|\\lambda_i|<=1，假设其中一个\\lambda=1，步长足够大时，仅有一项为1，其余为0，证明了马氏链的可收敛性",
    "q^{t+1}(x=j)=\\sum_{i=1}^K q^t(x=i)Q_{ij}   \n",
    "假设$\\pi$为一个概率分布$\\pi,\\pi(x^*)=\\int \\pi(x)p(x->x*)dx$,那么序列${\\pi(k)}$是一个平稳分布     \n",
    "平稳的一个充分非必要条件：Detailed Balance,\\pi(x)P(x->x*)=\\pi(x*)P(x*->x),即是在m步之后，状态的概率分布不再发生改变  \n"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三.MCMC \n",
    "思想：设计Q，使得平稳分布q(z)~目标分布p(x)，不考虑q(x)的形式，只需要逼近即可取样，相较于之前的俩方法我们只需要设计一个状态转移矩阵，不需要整q(z)的形式          \n",
    "回顾模型目的：后验概率p(z)我们需要计算E_{p(z)}[f(z)]=\\int_z f(z)p(z)dz，我们要构造一个马氏链，使其平稳分布逼近p(x)，然后从平稳分布采样",
    "假设一个条件概率矩阵Q=[Q_{ij}],p(z)Q(z->z*)\\alpha(z,z*)=p(z*)Q(z*->z)\\alpha(z*,z),Q\\alpha即为新的转移概率P(z->z*)，\\alpha为接受率=min(1,\\frac{p(z*)Q(z*->z)}{p(z)Q(z->z*)})",
    "Metropolis-hastings:$u~U(0,1)$,$z^i~Q(z|z^{i-1})$,$\\alpha=min(1,\\frac{p(z*)Q(z*->z)}{p(z)Q(z->z*)})$,如果u<=\\alpha,z^i=z*,否则，z^i=z^{i-1},注意，\\alpha中p为\\hat{p}",
    "Gibbs，针对p(z)高维，对不同维度单独采样，z_i~p(z_i|z_{i-1})    \n",
    "i:z_1^t,z_2^t,z_3^t        \n",
    "ii.t+1:z_1^{t+1}~p(z_1|z_2^t,z_3^t)               \n",
    "Gibbs的接受率为1，z_{-i}*与z_{-i}同分布        \n",
    "模型的初始状态可以随意设定，每次状态转移即可视为一个条件概率，在进入平稳阶段前的阶段叫燃烧期(bum-in)，时间叫mixing time        \n",
    "但是MCMC也有几个问题：1）理论只保证收敛性，但没有成熟的理论检查是否达到了m（进入平稳分布）；2）mixing time过长，p(x)太复杂的情况，高维且相关（e.x.多峰情况，难以逃逸）；3）好的采样，样本之间最好的独立的，但是MCMC采样得出的是相关的（马尔科夫链导致的）"
   ]
  }
   ],
   "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
