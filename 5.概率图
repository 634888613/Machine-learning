1.概率图
把概率模型的特征嵌入图模型
1.1高维随机变量
sum rule
product rule
chain rule
bayesian rule
困境：纬度高，计算量过大——简化模型
1)假设维度之间相互独立;2)马尔可夫性——条件独立性假设
概率图模型三大部分
表示：有向图；高斯图；无向图
推断：精确推断；近似推断（确定性近似-变分推断；随机近似）
学习：参数学习（完备数据；隐变量）；结构学习（学习图的结构）

2.贝叶斯网络
几种有向图：
p(c|a)=p(c|a,b) c独立于b|a:c<-a->b（条件独立）
a->b->c 给定b，a,c条件独立
a->c<-b 默认情况下，a,b独立，若c被观测，a,b不独立（路径是通的），因子分解与chain rule推导可得
a->;c->b->d,若d被观测，也是连通的
判断有向图是否是条件独立的：D-Seperation--全局马尔可夫性
markov blanket，点与其他点的关系等价于点与与之相关的点的关系
2.1贝叶斯网络相关的模型举例：
朴素贝叶斯：用于分类，x_i 独立于 x_j|y
混合：GMM-用于聚类，Z为k类（离散），z->x
增加时间维度：Markov Chain；Gaussian process（无限维高斯分布）
离散->连续：Gaussian Bayesian Network
混合模型+时间-动态模型：HMM(隐状态为离散)；线性动态系统（Kalmm filter-连续-gaussian且线性）；Particle Filter（非高斯；非线性）
从单一到混合；有限到无限-空间无限（离散-连续）+时间无限

3.马尔可夫随机场
无向图模型相较有向图更好解释
条件独立性体现在三个方面：全局<=>局部<=>成对
全局：x_A独立于x_C|x_B
local markov：给定邻居，与其他独立
成对 markov：x_i 独立于x_j|x_{-i,-j}
因子分解：相较于有向图，无向图因子分解较为复杂
概念补充：团-一个关于结点的集合，集合的节点之间互相连通；P(x)=1/z \product \phi(x_c_i) z为归一化因子，使后面的函数归一化为概率；
其中，C_i为最大团；x_C_i为最大团随机变量集合，\phi(x_c_i)为势函数且必须为正，一般使用energy function；\phi(x)=exp[-E(x_c_i)]
可证明，p(x)称为Gibbs Distribution，且为指数族分布（结合最大熵概念，最大熵原理推出来的也是Gibbs分布）
基于Hammesley-Clifford定理，基于最大团因子分解可以作用于马尔可夫场

4.Inference


