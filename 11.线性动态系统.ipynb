{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "近似推断/精确推断，其中近似推断重的随即推断中最著名的即为MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一.线性动态系统(Kalman Filter)  \n",
     "线性动态系统,Linear Gaussian--Kalman Filter;非线性动态系统，Non-Linear,Non-Gaussian      \n",
     "线性动态系统的表达：z_t=Az_{t-1}+B+\\epsilon x_t=Cz_t+D+\\delta,\\epsilon~N(0,Q),\\delta~N(0,R)，也可以表达为P(z_t|z_{t-1})~N(Az_{t-1}+B,Q),P(x_t|z_t)~N(Cz_t+D,R),初始状态z_1~N(\\mu_1,\\sum_1),参数\\theta=(A,B,C,D,Q,R,\\mu_1,\\sum_1)   \n",
     "滤波问题要参考前向算法的思想，P(z_t|x_1...x_t)正比于P(x_1....x_t,z_t)=P(x_t|x_1,x_2...x_{t-1},z_t)=P(x_t|z_t)P(x_1...x_{t-1},z_t)=P(x_t|z_t)P(z_t|x_1...x_{t-1})(一个预测问题)P(x_1,..x_{t-1})   \n",
     "P(z_t|x_1...x_{t-1})=\\int_z_{t-1} P(z_t,z_{t-1}|x_1...x_{t-1})dz_{t-1}=\\int_z_{t-1} P(z_t|z_{t-1},x_1...x_{t-1})P(z_{t-1}|x_1...x_{t-1}dz_{t-1}),得到递推式   \n",
     "步骤：t=1，P(z_1|x_1),update；t=2，P(z_2|x_1),prediction;t=2,P(z_2|x_1,x_2),P(z_3|x_1,x_2)...   \n",
     "因为正态分布假设，根据性质可以获得封闭解,x~N(\\mu,\\Lambda^{-1})精度矩阵-方差矩阵的逆,P(y|x)=N(y|Ax+b,L^{-1}),P(y)=N(y|A\\mu+b,L^{-1}+A\\Lambda^{-1}A^T)   \n",
     "step1,prediction:N(\\mu_t*,\\sum_t*)=\\int N(z_t|Az_{t+1}+B,Q)N(\\mu_{t-1},\\sum_{t-1})   \\mu_t*=A\\mu_{t-1}+B,\\sum*=Q+A\\sum_{t-1}A^T--step2 update N(\\mu_t,\\sum_t) 正比于N(X_t|Cz_t+D,R)N(\\mu_t*,\\sum_t*)",
     "最后p(z_t|x_t)正比于P(x_t|z_t)P(z_t)"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二.Particle Filter  \n",
    "相较于Kalman Filter particle由于形式不确定，可以使用蒙特卡洛进行近似，P(z|x),E_{z|x}[f(z)]=\\int=\\sum",
    "importance sampling:E[f(z)]=\\int f(z)p(z)dz=\\int f(z)\\frac{p(z)}{q(z)}q(z)dz=1/N\\sum f(z)\\frac{p(z)}{q(z)},也理解为权重 ,q(z),z^i~q(z),q(z)称为提议分布",
    "Filtering P(z_t|x_{1:t}),weight十分难以计算，对于每个时刻，需要计算w_i^1--w_i ^N，考虑不同时间节点之间的关系",
    "引出，Sequential Importance Sampling SIS.寻找w_t^i,w_{t-1}^i之间的关系，进而减少关于w的计算量，P(z_{1:t}|x_{1:t})=1/c P(x_t|z_t)P(z_t|z_{t-1})P(z_{1:t-1},x_{1:t-1})=\\frac{D}{C}P(x_t|z_t)P(z_t|z_{t-1})P(z_{1:t-1},x_{1:t-1})",
    "由于q是我们自己设定的，假设q(z_{1:t}|x_{1:t})=q(z_t|z_{1:t-1},x_{1:t})q(z_{1:t-1}|x_{1:t-1}),将两个公式代入w_t^i,可得到递推式",
    "算法总结，前提：t-1时刻系统已经完成，z_t^i~q(z_t|z_{t-1},x_{1:t}) w_t^i正比于w_{t-1}^i\\frac{P(x_t|z_t)P(z_t|z_{t-1})}{q(z_t|z_{t-1}x_{1:t})}，对w进行归一化",
    "问题：权值退化，运行一定步数之后，w会越来越小，越来越不平均（高维所导致）应对方法一般两种，resampling；选择一个合适的proposal dist q(z)",
    "重采样：以例子的权重为离散分布，权重大的采样的概率就大；q(z)的选择，q(z_{1:t-1},x_{1:t})=p(z_t|z_{t-1})w_{t-1}^i=>w_t^i=p(x_t|z_t^i)w_{t-1}^i,优化后，即为SIR Filter"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三.HMM \n",
    "HMM是一个混合模型并增加时间轴，与GMM进行类比，可以把HMM理解为GMM增加时间，HMM对于发射矩阵没有特定要求，也可以为概率分布，只需要i为离散   \n",
     "动态模型-state space model状态空间模型，针对解决两大问题，1）learning 问题，通过数据学习参数；2）inference：推断后验概率P(z|x)，数据与数据之间可能存在在关联，作用：1）decoding，给定观测序列，求隐状态序列P(z_1...z_t|x_1,x_2,x_t);2)prob of evidence:P(x|\\theta)=P(x_1,x_2...x_T|\\theta) 使用前向或后向算法;3)filtering:P(z_t|x_1,...x_t),滤波问题，因为拿到了更多的历史数据，可以过滤掉更多的噪声->在线学习，P(z_t|x_{1:t})正比于\\alpha_t；4)smoothing P(z_t|x_1...x_T)->offline，P(x_{1:T},z_t)=P(x_{t+1,T}|x_{1:t},z_t)P(x_{1:t},z_t)正比于P(x_{t+1:T},z_t)=\\alpha_t\\beta_t，转换时，使用概率图中条件独立的思想,前向后向算法；5)prediction，P(z_{.}/x_{.}|x_1,x_2...x_t)，P(Z_{t+1}|x_{1:t})=\\sum P(z_{t+1},z_t|x_{1:t})=\\sum P(z_{t+1}|z_t,x_{t+1})P(z_t|x_{1:t})P(z_{t+1}|z_t)这就是filtering问题了，P(x_{t+1}|x_{1:t})=\\sum P(x_{t+1},z_{t+1}|x{1:t})=\\sum P(x_{t+1}|z_{t+1},x{1:t})P(z_{t+1}|x_{1:t})    \n",
   ]
  }
   ],
   "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
